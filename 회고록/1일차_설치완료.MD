# Docker CUDA toolkit isntall

```shell
docker run --gpus all -d --name cuda nvidia/cuda:12.2.0-devel-ubuntu22.04 sleep infinity
docker exec -it my_cuda_container /bin/bash
nvcc -o my_program my_program.cu
./my_program
```

```shell
docker exec my_cuda_container bash -c "cd /workspace && nvcc -o my_program my_program.cu && ./my_program"
docker exec -w /workspace my_cuda_container ./my_program
```

- 간단히 실행하려면 이렇게 해보자. 컴파일 끝난 파일을 바로 실행할 수 있도록

# Writing Application Code for the GPU

```c
#include <stdio.h>
 
void CPUFunction()
{
    printf("This function is defined to run on the CPU.\n");
}
 
__global__ void GPUFunction()
{
    printf("This function is defined to run on the GPU.\n");
}
 
int main()
{
    CPUFunction();
 
    GPUFunction<<<1, 1>>>();
    cudaDeviceSynchronize();
}
```

```c
__global__ void GPUFunction()
{
    printf("This function is defined to run on the GPU.\n");
}
```
- 위 코드에서 global은 cpu, gpu에서도 부를 수 있다는 의미
- 중요한 점은 이 함수의 return값은 항상 void여야함.
- 이렇게 정의한 GPU함수는 일반적으로 커널(kernel)이라고 부르며 런치(launch)한다고 함

![image](https://github.com/user-attachments/assets/4e3a68dd-03c5-4813-98cb-0a8cf3728798)

> 위 사진은 docker 화면에서 nvcc 컴파일 후, 실행한 화면이다.
> 나는 그리드와 박스를 1, 1로 넣었지만 만약 5, 5를 넣게된다면 25개 쓰레드로 25번이 출력이 될것이다.

```c
GPUFunction<<<2, 4>>>();
// 2 box, 4 쓰레드, 총 8쓰레드
```

![image](https://github.com/user-attachments/assets/95e0ceb2-d564-4056-a292-5a7d777f3289)

